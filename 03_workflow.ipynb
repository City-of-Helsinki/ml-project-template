{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp workflow\n",
    "%load_ext lab_black\n",
    "# nb_black if running in jupyter\n",
    "%load_ext autoreload\n",
    "# automatically reload python modules if there are changes in the\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "> Define static or dynamic workflow for automatically updating, training and deploying your ML model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***input:*** Workflow definition parameters\n",
    "\n",
    "***output:*** python or snakemake script for running the workflow\n",
    "\n",
    "***description:***\n",
    "\n",
    "While you are developing your ML application, you might prefer running the notebooks manually again and again.\n",
    "However, once you have deployed your model into production it becomes unpractical and compromizes scalability, modularity and the principle of ease of reproducibility.\n",
    "This happens regardless of what 'production' means to you - it might well be that you are just running the notebooks and viewing the results directly from them.\n",
    "Whatever you are doing, having a single command to run the whole workflow makes things so much easier.\n",
    "\n",
    "Workflow automation is also the part of the work where you'll probably notice a lot of bugs and nonrobustness in your notebooks.\n",
    "Probably a lot more than you anticipated, but try not to get frustrated! Debugging is big and important part of the work.\n",
    "\n",
    "In this notebook we explain alternatives for automating workflows, either as a static or dynamic. \n",
    "By following these examples (and further documentation on [papermill](https://papermill.readthedocs.io/) and [Snakemake](https://snakemake.readthedocs.io/)) you can parameterize your notebooks,\n",
    "run them automatically in a workflow, and even parameterize and automate the workflow definition.\n",
    "With this template, you can easily define very complex and versatile workflows, that are well documented in a notebook. \n",
    "\n",
    "We selected these tools for the template because they have stable community support, they are relatively easy to use and they fit our needs.\n",
    "There are also other tools for workflow management and orchestration that may better suite your needs. Feel free to use them.\n",
    "For more information, see for example this \n",
    "[comparison of workflow tools for Python](https://medium.com/@Minyus86/comparison-of-pipeline-workflow-packages-airflow-luigi-gokart-metaflow-kedro-pipelinex-5daf57c17e7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is tagged with 'parameters'\n",
    "\n",
    "save_notebooks_to = (\n",
    "    \"results/.notebooks/\"  # TODO: make example of timestamping notebook runs\n",
    ")\n",
    "\n",
    "## NOTE: copies of executed notebooks are saved to hidden folder, because currently nbdev searches\n",
    "## all subfolders when building docs, and the notebook copies may cause confusing results.\n",
    "## hidden folders should be ignored.\n",
    "## See more: https://github.com/fastai/nbdev/issues/357\n",
    "## TODO: follow updates on nbdev, see if there is a cleaner fix to this!\n",
    "\n",
    "# notebook names\n",
    "index = \"index.ipynb\"\n",
    "index_params = {}\n",
    "\n",
    "data = \"00_data.ipynb\"\n",
    "data_params = {}\n",
    "\n",
    "model = \"01_model.ipynb\"\n",
    "model_params = {}\n",
    "\n",
    "loss = \"02_loss.ipynb\"\n",
    "loss_params = {}\n",
    "\n",
    "workflow = \"03_workflow.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make direct derivations from the paramerters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom magic function to write code cell contents to a file with global variables formatted:\r\n",
    "\r\n",
    "This is needed so that we can create parameterizable non-python scripts from inside a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writefile_format_globals(filename, cell):\n",
    "    \"\"\"\n",
    "    This is a function to write contents of a notebook cell to a file.\n",
    "    To use it, call '%%writefile_format_globals filename' in the first row of\n",
    "    the cell the contents of which you want to write into a file.\n",
    "    The code written in this cell is not run in the notebook.\n",
    "    This means that you can also write and define non-python scripts and\n",
    "    execute them from a notebook.\n",
    "\n",
    "    You can format in global variables by placing them inside curly\n",
    "    brackets '{variable name}'.\n",
    "\n",
    "    Note, that your code should not include curly brackets.\n",
    "    If curly brackets need to be written in the file, you can include\n",
    "    them through the variable insertion:\n",
    "\n",
    "    ## CELL 1:\n",
    "    bracket_open_string = '{'\n",
    "    bracket_close_string = '}'\n",
    "\n",
    "    ## CELL 2:\n",
    "    %write_format_globals myscriptname\n",
    "    {bracket_open_string}\n",
    "        # I want this part inside curly brackets!\n",
    "    {bracket_close_string}\n",
    "\n",
    "    ## file 'myscriptname' after running the cells 1 and 2:\n",
    "    {\n",
    "        # I want this part inside curly brackets!\n",
    "    }\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run parameterized notebooks with papermill\r\n",
    "\r\n",
    "Papermill allows parameterizing and running notebooks from Python runtime with `papermill.execute_notebook(input, output, parameters)`.\r\n",
    "The `input` parameter is the notebook to be run. The `output` parameter is the filepath where copy of the executed notebook is saved with the results.\r\n",
    "This can be the same as the `input`, but you probably want to keep it separate - otherwise your version control may get messy. \r\n",
    "In this example executed notebooks are saved under `results/notebooks`. The `parameters` cell allows you to change settings of the notebooks.\r\n",
    "\r\n",
    "You may have noticed, that in the beginning of each notebook there is a cell with a comment `# This cell is tagged parameters`.\r\n",
    "The cell has been added 'Parameters` tag. The template notebooks already contain the tag, \r\n",
    "but you can see [here](https://papermill.readthedocs.io/en/latest/usage-parameterize.html) how to do it on different notebook editors.\r\n",
    "In this cell, variables are assigned. What papermill does is, that any parameters given to the `execute_notebook` function are listed \r\n",
    "in a new cell right below the one tagged with parameters. The listed parameters will rewrite the default assignments.\r\n",
    "This is why you should not do anything else but simple assignments in the parameters cell.\r\n",
    "\r\n",
    "Let's show an example. Let's run the notebook 'model' with and without changing the 'seed'-parameter.\r\n",
    "You can then compare the resulting notebooks in `results/notebooks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb40478d62c4df698db81e546d7c3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/43 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "# run model notebook with default parameters\n",
    "_ = pm.execute_notebook(\n",
    "    \"02_loss.ipynb\",\n",
    "    \"results/.notebooks/02_loss_default_params.ipynb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff5ccfab18c4de7be1ba82ba307a0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/44 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# slow\n",
    "# run model notebook with 'seed' -parameter changed from 0 to 1\n",
    "_ = pm.execute_notebook(\n",
    "    \"02_loss.ipynb\", \"results/.notebooks/02_loss_seed_1.ipynb\", parameters={\"seed\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now compare the results. \n",
    "\n",
    "Copies of the executed notebooks are saved in a hidden folder, so that they don't confuse nbdev.\n",
    "Notebooks can not be viewed from hidden folders, so you have to make a visible copy of the folder.\n",
    "This may appear a bit unpractical, and we hope to find a more convenient solution in the future (without making custom edits to nbdev).\n",
    "However, in practice this rarely matters since the location where you save the notebooks can be outside the project folder, and it only serves as a backup\n",
    "so you probably don't need to view the automatically executed notebooks that often.\n",
    "\n",
    "How to move the notebooks from one folder to another in shell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    cp -r results/.notebooks/ results/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then open the notebooks as usual in your editor. See how changing the seed changes the results?\n",
    "Now, before you build the modules and docs with `nbdev_build_lib && nbdev_build_docs`, remember to delete the notebook files from under results folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    rm -r results/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static executable workflow with papermill\n",
    "\n",
    "Now we can define a simple static parameterizable workflow. The workflow is a Python script, completely defined in this notebook for consistent of documentation (everything is defined in notebooks). We then export the script into a file, so that it can be executed outside this notebook. We added the script file to gitignore, because it is defined in this notebook and will be recreated every time this notebook is run. We define the script parameterization so, that the parameters are hard coded into the script file when it is generated, based on this notebook. So, to change the setup, you should run this notebook with different parameters. You may make different choises, but consider ease of reproducibility and be sure to document your work well.\n",
    "\n",
    "Now run the cell below to create the execution script (the code is not run in this notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_format_globals static_workflow.py\n",
    "# execute workflow of the example notebooks\n",
    "# to run the script, call python static_workflow.py\n",
    "# this file has been added to .gitignore\n",
    "# NOTE: use curly brackets only to format in global variables!\n",
    "# hint: you can include additional parameters with sys.argv\n",
    "\n",
    "# import relevant libraries\n",
    "import papermill as pm\n",
    "\n",
    "# update modules\n",
    "\n",
    "# optional (uncomment): make backup of index:\n",
    "# _ = pm.execute_notebook(\"{index}\", \"{save_notebooks_to}{index}\")\n",
    "\n",
    "# run data notebook\n",
    "_ = pm.execute_notebook(\"{data}\", \"{save_notebooks_to}{data}\")\n",
    "# remember that you can change the notebook parameters by giving \n",
    "# the execute_notebook function parameter dict:\n",
    "# parameters = dict(parameter_name_string:parameter_value, ...)\n",
    "\n",
    "# run model notebook\n",
    "_ = pm.execute_notebook(\"{model}\", \"{save_notebooks_to}{model}\")\n",
    "# run loss notebook\n",
    "_ = pm.execute_notebook(\"{loss}\", \"{save_notebooks_to}{loss}\")\n",
    "\n",
    "# optional (uncomment): make backup of the workflow notebook:\n",
    "# import os\n",
    "# os.system('cp {workflow} {save_notebooks_to}{workflow}')\n",
    "# (a recursive call with pm could also work,\n",
    "# but only do it if you known what you are doing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open the file `static_workflow.py`, you notice that the contents of curly brackets were replaced with the parameters of this notebook.\n",
    "\n",
    "Now, you can run the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing:   0%|                                       | 0/57 [00:00<?, ?cell/s][IPKernelApp] WARNING | Unknown error in handling startup files:\n",
      "Executing: 100%|██████████████████████████████| 57/57 [00:21<00:00,  2.86cell/s]\n",
      "Executing:   0%|                                       | 0/44 [00:00<?, ?cell/s][IPKernelApp] WARNING | Unknown error in handling startup files:\n",
      "Executing: 100%|██████████████████████████████| 44/44 [00:22<00:00,  2.02cell/s]\n",
      "Executing:   0%|                                       | 0/43 [00:00<?, ?cell/s][IPKernelApp] WARNING | Unknown error in handling startup files:\n",
      "Executing: 100%|██████████████████████████████| 43/43 [00:17<00:00,  2.98cell/s]\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "!python static_workflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can again make a visible copy of the hidden notebooks folder just like above (remember to delete it afterwards) and view the notebooks.\n",
    "You can change some of the notebook parameters and rerun the workflow to see how it effects the results.\n",
    "\n",
    "You see that static workflow definition is quite simple. In the script above, \n",
    "we did not define any inputs, outputs or the relation of the different steps.\n",
    "It's good to keep things that way, unless there is a reason not to.\n",
    "It might be that we have multiple, changing data sources, complex workflow structure,\n",
    "need for parallelization or other issues making it either difficult to hard-code\n",
    "the steps required in your workflow. Then, you might need a dynamic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic executable workflow with Snakemake\n",
    "\n",
    "Snakemake is a tool that will automatically determine which steps to run based on inputs and outputs.\n",
    "It's like gnu make, but for Python: easy to read and write, but powerful.\n",
    "Here we only cover a tiny portion of the possibilities of snakemake, but it can do very complex things.\n",
    "One thing to notice is that Snakemake must be the root runtime of Python - you can not lauch it from inside a Python script (at least with the current version).\n",
    "\n",
    "The following script will be written into a Snakefile, that you can run to execute the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (templateenv)",
   "language": "python",
   "name": "templateenv_py3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
