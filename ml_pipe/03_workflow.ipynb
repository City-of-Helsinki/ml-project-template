{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp workflow\n",
    "%load_ext lab_black\n",
    "# nb_black if running in jupyter\n",
    "%load_ext autoreload\n",
    "# automatically reload (local) python modules if they are updated\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "    Define workflow for automatically updating, training and deploying your ML model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***input:*** data, model & loss notebooks and related modules\n",
    "\n",
    "***output:*** script for executing the ML model update workflow\n",
    "\n",
    "***description:***\n",
    "\n",
    "A ML model update workflow allows you to automatically reload your data, train, evaluate and deploy your model.\n",
    "Note that by following the notebook templates you have already done most of the work - the notebooks **are** the workflow!\n",
    "\n",
    "So, in this notebook you define a script to automatically execute the other notebooks with the [papermill](https://papermill.readthedocs.io/) tool. Note, that you can input parameters to the notebooks!\n",
    "\n",
    "You can either define static workflow, where every step is always recreated every time,\n",
    "or a dynamic workflow, where only the parts of the workflow are recreated that are affected by the changes since last model update.\n",
    "For dynamic workflows we encourage utilizing the [Snakemake](https://snakemake.readthedocs.io/) tool.\n",
    "\n",
    "Here we present a super simple static workflow example that you can build upon in your project. \n",
    "\n",
    "Edit this and other text cells to describe your project. \n",
    "\n",
    "Remember that you can utilize the `#export` tag to export cell commands to `[your_module]/workflow.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import papermill\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged with 'parameters'\n",
    "seed = 0\n",
    "backup_name_base = \"run_\"\n",
    "timestamp = True\n",
    "run_id = \"setup_1\"\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make direct derivations from the paramerters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define workflow\n",
    "\n",
    "Here we present a tiny example you can try running yourself and then extend to your needs.\n",
    "\n",
    "Note that if you run `nbdev_build_lib`, the script is exported to `[your_module]/workflow.py`.\n",
    "\n",
    "Then, you can run `python [your_module]/workflow.py` to run the workflow automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input notebook does not contain a cell with tag 'parameters'\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Executing: 100%|██████████| 30/30 [00:01<00:00, 19.31cell/s]\n",
      "Executing: 100%|██████████| 25/25 [00:01<00:00, 20.83cell/s]\n",
      "Executing: 100%|██████████| 31/31 [00:01<00:00, 25.48cell/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A workflow to re-run your machine learning workflow automatically.\n",
    "\n",
    "This example script will\n",
    "- rebuild your python module\n",
    "- run data notebook to reload and clean data\n",
    "- run model notebook to sw test your model\n",
    "- run loss notebook to train and evaluate your model with full data,\n",
    "    and save or deploy it for further use\n",
    "\n",
    "Feel free to edit!\n",
    "\"\"\"\n",
    "\n",
    "# create name for backup folder folder\n",
    "run_name = backup_name_base + run_id + \"_\"\n",
    "if timestamp:\n",
    "    run_name += datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "run_name = run_name.rstrip(\"_\")\n",
    "\n",
    "# create backup folder if it does not exist\n",
    "cwd = Path().cwd()\n",
    "backup_path = cwd.parent / \"local_data\" / \"ml_pipe_backups\" / run_name\n",
    "\n",
    "try:\n",
    "    backup_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:  # do not overwrite\n",
    "    pass\n",
    "\n",
    "# make sure changes are updated to module\n",
    "# (this will do nothing if you run the workflow from inside a notebook)\n",
    "os.system(\"nbdev_export\")\n",
    "\n",
    "# run workflow\n",
    "for notebook in [\n",
    "    \"00_data_etl.ipynb\",\n",
    "    \"01_model_class.ipynb\",\n",
    "    \"02_train_test_validate.ipynb\",\n",
    "]:\n",
    "    papermill.execute_notebook(\n",
    "        notebook,  # this notebook will be executed\n",
    "        backup_path\n",
    "        / (\"_\" + notebook),  # this is where the executed notebook will be saved\n",
    "        # (notebooks named with '_' -prefix are ignored by nbdev build_lib & build_docs!)\n",
    "        parameters={\"seed\": 1},  # you can change notebook parameters\n",
    "        # kernel_name=\"python38myenv\",\n",
    "    )  # note: change kernel according to your project setup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also define your workflow in another language than Python and write it into a file from this notebook utilizing the %%writefile magic.\n",
    "This way your script is still included the documentation without copy-pasting.\n",
    "You can also add the script to .gitignore to avoid double tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can now move on to API notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
