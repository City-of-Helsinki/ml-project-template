---

title: Model


keywords: fastai
sidebar: home_sidebar



nb_path: "01_model.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_model.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>input</em></strong>: toy dataset from data-notebook</p>
<p><strong><em>output</em></strong>: python module containing ML model class</p>
<p><strong><em>description:</em></strong></p>
<p>In this notebook you hypothetize, explain and explore machine learning models to solve your problem.</p>
<p>Then, you should encapsulate the model inside a Python class to be exported into <code>your_repository/your_module/model.py</code>,
so that it can be evaluated in the loss notebook, and intergrated with your target application.
Repository name and module name are the same by default.
You should also unit test the classes created in this notebook with the toy data created in data notebook.</p>
<p>You should probably have a person in your team familiar with object oriented programming with python and unit testing, but if not, don't worry.
If you can explore by scripting in the cells and create a draft of the properties and functions you want to have, and that's a great start.
Then, any Python developer can easily build the model class for you.
However, we encourage you to learn more on <a href="https://realpython.com/python3-object-oriented-programming/">object oriented programming with Python</a>
and <a href="https://realpython.com/python-testing/">getting started with unit testing in Python</a>.
You can also follow the example here to create your own simple machine learning Python class.</p>
<p>This notebook contains an example ML model for classifying the heart disease dataset with logistic regression.</p>
<p>The example is split into a base class and a subclass for demonstrating class inheritance of Python.
You can probably just write one class that contains all the attributes and functions you need, without inheriting anything.
However, alternative implementations of a model might be implemented in separate subclasses, for example.
You can also define multiple classes, for example one for ML model and another for optimization.
If the methods are complicated or you are comparing multiple methods that don't share common functions, 
you can also separate models or subclasses to different notebooks similar to this.
Adjust the running number, name, header and top cell <code>#default_exp module_name</code> of the notebooks accordingly.</p>
<p>Remember to add <code># export</code> to top of all cells containing functions or classes that you have defined and want to use outside this notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Import-relevant-modules">Import relevant modules<a class="anchor-link" href="#Import-relevant-modules"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># plot functions from data notebook</span>
<span class="kn">from</span> <span class="nn">ml_project_template.data</span> <span class="kn">import</span> <span class="n">plot_trellis</span><span class="p">,</span> <span class="n">plot_histogram</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Define-parameters">Define parameters<a class="anchor-link" href="#Define-parameters"> </a></h2><p>Remember, only simple assignments here!</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Make immediate derivations from the parameters:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Import-toy-data-for-testing">Import toy data for testing<a class="anchor-link" href="#Import-toy-data-for-testing"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">toy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;data/preprocessed_data/dataset_toy_switzerland_cleveland.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
<span class="n">toy_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1age</th>
      <th>x4trestbps</th>
      <th>x8thalach</th>
      <th>x10oldpeak</th>
      <th>y1num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>53.0</td>
      <td>142.0</td>
      <td>111.0</td>
      <td>0.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>56.0</td>
      <td>200.0</td>
      <td>133.0</td>
      <td>4.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>62.0</td>
      <td>140.0</td>
      <td>143.0</td>
      <td>0.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>53.0</td>
      <td>160.0</td>
      <td>122.0</td>
      <td>0.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>54.0</td>
      <td>160.0</td>
      <td>163.0</td>
      <td>0.0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>Note, that depending on your choice of file format and your variables, you might have to redefine data types once you load data!</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explain-the-math-behind">Explain the math behind<a class="anchor-link" href="#Explain-the-math-behind"> </a></h2><p>Give a short explanation of how the algorithms work that you are planning to use.</p>
<p>For industrial use, you can keep this light and simple: you can provide links to external sources for further reading.</p>
<p>For research, you might want to dig deeper - this is your core documentation, after all!</p>
<p>You can use $\LaTeX$ notation to write math symbols and equations:</p>
$$
Pr(Y_i=1|X_i) = {\frac{exp(\beta_0 + \beta_1X_i + \dots + \beta_nX_n)}{1 + exp (\beta_0 + \beta_1X_i + \dots + \beta_nX_n)}}
$$<p>You can also draft algorithms:</p>

<pre><code>ALGORITHM
input: X
output: y

while: condition
    do thing</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Begin-with-simple-scripts-before-constructing-the-model-class">Begin with simple scripts before constructing the model class<a class="anchor-link" href="#Begin-with-simple-scripts-before-constructing-the-model-class"> </a></h2><p>This is the place where you can explore and play around with different machine learning operations.
Your goal is to plan and demonstrate the features and functions you want your machine learning class to have.
The good thing is, that you don't need to think about object oriented programming here.
Just assign variables and call functions.</p>
<p>It's good to define at least the following steps:</p>
<ol>
<li>Splitting data into training and testing data</li>
<li>Preprocess the data (scale, dimension reduction, convolutions etc.)</li>
<li>Define your model algorithm and fit it with toy data</li>
<li>Define your loss function - how do you evaluate your model?</li>
<li>Consider hyperparameter optimization</li>
<li>Try to pipe the previous steps</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's begin by splitting our data to train and test data</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">toy_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">toy_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># test size 1/k</span>

<span class="c1"># train_test_split does the job here</span>

<span class="c1"># stratify = y means, that both the testing and training dataset contain</span>
<span class="c1"># label values in same proportion as they are in the whole dataset</span>
<span class="c1"># it only works with categorical data, and might cause errors there</span>
<span class="c1"># if some category is rare</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># preprocessing: let&#39;s rescale the data</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="c1"># algorithm: logistic regression</span>
<span class="n">lgr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="c1"># pipe: let&#39;s join these two in a pipeline</span>
<span class="c1"># now the pipeline actually becomes our machine learning model:</span>
<span class="c1"># we can just call the pipe instead of first scaling data and then</span>
<span class="c1"># calling the algorithm functions separatedly</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">scaler</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;estimator&quot;</span><span class="p">,</span> <span class="n">lgr</span><span class="p">)])</span>
<span class="c1"># fit data</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># get test score</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.4
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># let&#39;s use f1  for loss here</span>
<span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.5714285714285715</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we optimize the model hyperparameters with cross validated grid search.
Notice that this is just an example: grid search is very ineffective and does not quarantee good optimization solutions for hyperparameters.
In real applications Bayesian optimization is usually a great solution.
You can skip optimization in the beginning and return to it in the later iterations of the project.
For example sklearn models usually have good default hyperparameters, and you may well get started with those.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">## hyperparameters to be optimized (be consistent with the naming)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;estimator__C&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
<span class="p">}</span>

<span class="c1"># create cross validation for grid search</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

<span class="c1"># create optimizer</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">pipe</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># fit optimizer</span>
<span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># view results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Estimator: </span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Parameters: </span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Test Score: </span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Best Training Score: </span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">gs</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_train_score&quot;</span><span class="p">][</span><span class="n">gs</span><span class="o">.</span><span class="n">best_index_</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All Training Scores: </span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_train_score&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All Test Scores: </span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">]))</span>

<span class="c1"># set pipe hyperparameters to the optimized:</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">estimator__C</span><span class="o">=</span><span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s2">&quot;estimator__C&quot;</span><span class="p">])</span>

<span class="c1"># fit pipe</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pipe test score with optimized hyperparams&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pipe</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best Estimator: 
Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;estimator&#39;, LogisticRegression(C=0.3593813663804626))])

Best Parameters: 
{&#39;estimator__C&#39;: 0.3593813663804626}

Best Test Score: 
0.75

Best Training Score: 
0.8375

All Training Scores: 
[0.6    0.6    0.6    0.65   0.8375 0.8375 0.8375 0.8375 0.8375 0.8375]

All Test Scores: 
[0.6  0.6  0.6  0.55 0.75 0.75 0.65 0.65 0.65 0.65]

Pipe test score with optimized hyperparams
0.4
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok, so we can fit a model to the data and it appears to do something (with the small test data we can not necessarily say if it's meaningful).</p>
<p>However, how would you take this script into production?
How would you scale it, or use it with completely different setup of data and parameters?
(well, this is a tiny example, so we could actually easily parameterize a script, but that's rarely the case in real world applications)</p>
<p>This is why we need to construct a model class, to hold all of the steps required in separate, tidy functions.
Then we can recreate the model and the steps with different data, without copy-pasting or manually editing all the tiny details.</p>
<p>Follow along the example - you'll see, that half the work was done in the scripting cells above!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Define-base-class-for-your-ML-model">Define base class for your ML model<a class="anchor-link" href="#Define-base-class-for-your-ML-model"> </a></h2><p>You will probably do just fine creating a one simple class that does not inherit anything.
You can then use this example base class as a template for your machine learning class. 
However, this is not always the case, and class inheritance is one of the most useful features of Python (and object oriented programming).
This is why we wanted to demonstrate a base class - subclass division.</p>
<p>Here we define the base class <a href="/ml_project_template/model.html#MachineLearningModel"><code>MachineLearningModel</code></a> that holds some simple functions for handling data, that would be common for all subclasses.
If a function only contains a <code>pass</code>-statement, it will be defined in the subclass.</p>
<blockquote><p><strong>Note</strong>:in this example the model instance contains the data. 
This is rarely applicable in practice if the data is large.
Instead, in most applications the model should be routed to query the data when needed, in a similar way that it would appear as if the model instance contained the data.</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MachineLearningModel" class="doc_header"><code>class</code> <code>MachineLearningModel</code><a href="https://github.com/City-of-Helsinki/ml_project_template/tree/master/ml_project_template/model.py#L23" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MachineLearningModel</code>(<strong><code>X</code></strong>, <strong><code>y</code></strong>, <strong><code>n_splits</code></strong>=<em><code>5</code></em>, <strong><code>seed</code></strong>=<em><code>0</code></em>)</p>
</blockquote>
<p>Overly simplified example for a base class:</p>
<p>data handling operations</p>
<p>handle definitions of other functions</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Unit-test-base-class">Unit test base class<a class="anchor-link" href="#Unit-test-base-class"> </a></h2><p>Purpose of unit testing is to cover all possible excecution paths in code.
Unit testing helps developers to avoid and identify bugs in code.</p>
<p>To unit test the class, we want to try and call every function of it and execute every different possible execution path.
The proportion of possible paths covered is called the test coverage.
100% coverage is rarely possible,
but it would be good to try and test the functions with good and bad input,
and with possible limit values (min, max, zero, None, np.nan, empty list etc.).</p>
<p>However, a few simple tests are easier to maintain (and to actually get done in the first place) than exhaustive unit testing.
Don't worry about coverage too much!
A few well considered tests are better than having none.</p>
<p>At the moment, nbdev considers all cells that do not have <code># export</code> tag as tests.
Unit tests can be defined with <code>assert</code> command - the nbdev git hooks run these commands when you push commits.
Cells with <code># slow</code> -tag will be omitted for time savings.</p>
<p>The line after <code>assert</code> should have a <code>True</code> or non-zero value.
<code>False</code>, 0 or None object will raise an <code>AssertionError</code>. Note that <code>np.nan</code> does not raise the error.</p>
<p>This is handy because you can now keep all your tests in the same file (notebook) with the code and documentation.
The downside is, however, that at the moment there is no good solution for monitoring test coverage of notebook developed code. 
If test coverage measuring is required, one option would be to implement tests with  <code>pytest</code> or <code>unittest</code> and export the tests to separate test.py file.</p>
<p>Let's begin by introducing a couple of super simple unit test examples:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">this_statement_is_true</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">assert</span> <span class="n">this_statement_is_true</span>

<span class="c1"># Another example of simple unit test of a function</span>
<span class="k">def</span> <span class="nf">return_three</span><span class="p">():</span>
    <span class="k">return</span> <span class="mi">3</span>


<span class="c1"># unit test return_tree</span>
<span class="k">assert</span> <span class="n">return_three</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span>

<span class="c1"># Third example of simple unit testing of a simple class</span>
<span class="k">class</span> <span class="nc">SimpleClass</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple class that stores an attribute and has a function to return it</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span> <span class="o">=</span> <span class="n">parameter</span>

    <span class="k">def</span> <span class="nf">get_attribute</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span>


<span class="c1"># unit thest init (should return class instance)</span>
<span class="k">assert</span> <span class="n">SimpleClass</span><span class="p">(</span><span class="s2">&quot;hello world!&quot;</span><span class="p">)</span>
<span class="c1"># unit test get_attribute (should return &#39;Hello world!&#39;)</span>
<span class="k">assert</span> <span class="n">SimpleClass</span><span class="p">(</span><span class="s2">&quot;Hello world!&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get_attribute</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;Hello world!&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the assert commands run without an error, the tests pass.</p>
<p>Now, let's include some tests with our example ML base class:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">MachineLearningModel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">mlmodel</span> <span class="o">=</span> <span class="n">MachineLearningModel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># test get_data</span>
<span class="k">assert</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">get_data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">get_data</span><span class="p">()[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># test __create_test_train_data and get_train_test_data</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
    <span class="mi">10</span> <span class="o">*</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">get_train_test_data</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">get_data</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="mi">10</span> <span class="o">/</span> <span class="n">mlmodel</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span>

<span class="c1"># test set_data (you should be able to change the model data completely)</span>
<span class="k">assert</span> <span class="p">(</span>
    <span class="n">MachineLearningModel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># create model as usual</span>
    <span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># reset data in reverse order</span>
    <span class="o">.</span><span class="n">get_data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># get data</span>
    <span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="p">)</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span>
    <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
<span class="p">]</span>  <span class="c1"># first element is now reversed to last</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Define-subclasses-&amp;-functions">Define subclasses &amp; functions<a class="anchor-link" href="#Define-subclasses-&amp;-functions"> </a></h2><p>A subclass or child class inherits all attributes and functions of a parent class, but may also have additional functions defined.</p>
<p>Here we define an example of a subclass of <a href="/ml_project_template/model.html#MachineLearningModel"><code>MachineLearningModel</code></a>, the <code>LogisticRegressionModel</code> which performs logistic regression:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LogisticRegressionClassifier" class="doc_header"><code>class</code> <code>LogisticRegressionClassifier</code><a href="https://github.com/City-of-Helsinki/ml_project_template/tree/master/ml_project_template/model.py#L130" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LogisticRegressionClassifier</code>(<strong><code>X</code></strong>, <strong><code>y</code></strong>, <strong><code>n_splits</code></strong>=<em><code>5</code></em>, <strong><code>seed</code></strong>=<em><code>0</code></em>) :: <a href="/ml_project_template/model.html#MachineLearningModel"><code>MachineLearningModel</code></a></p>
</blockquote>
<p>Logistic regression classifier</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Unit-test-subclasses">Unit test subclasses<a class="anchor-link" href="#Unit-test-subclasses"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">LogisticRegressionClassifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">lgr_model</span> <span class="o">=</span> <span class="n">LogisticRegressionClassifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># test fit</span>
<span class="k">try</span><span class="p">:</span>  <span class="c1"># fit should be called before predict or score</span>
    <span class="n">lgr_model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># so this will cause an error</span>
<span class="k">except</span><span class="p">:</span>  <span class="c1"># but the except statement catches the error</span>
    <span class="k">pass</span>  <span class="c1"># yes, you can also test what should not work!</span>

<span class="c1"># there are two ways we can call the fit function: with and without data</span>
<span class="k">assert</span> <span class="n">lgr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">lgr_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># test predict</span>
<span class="k">assert</span> <span class="n">lgr_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[::</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
<span class="c1"># test loss</span>
<span class="k">assert</span> <span class="n">lgr_model</span><span class="o">.</span><span class="n">get_train_loss</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">lgr_model</span><span class="o">.</span><span class="n">get_test_loss</span><span class="p">()</span>

<span class="c1"># test get_params</span>
<span class="k">assert</span> <span class="n">lgr_model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In addition, we might observe that our model is very slow (this example is not).</p>
<p>Then, we could try to evaluate how much time each of the functions,
and even the contents of the functions take to identify the bottlenecks.
The theory of <a href="https://en.wikipedia.org/wiki/Big_O_notation">order of functions</a> may also be useful.</p>
<p>However, this is something you should only do in the late stages of your project.
Remember, thinking time is what matters in data science!
Begin with overoptimizing things, and you'll never have results.</p>
<p>Anyway, you can easily time functions in notebooks with <code>%%timeit</code> <a href="https://ipython.readthedocs.io/en/stable/interactive/magics.html">magic command</a>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it
<span class="n">LogisticRegressionClassifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>UsageError: Line magic function `%%timeit` not found.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Visualize-model-behaviour-with-toy-data">Visualize model behaviour with toy data<a class="anchor-link" href="#Visualize-model-behaviour-with-toy-data"> </a></h2><p>Now, with the unit tests we can assume that our model does something right.
At least any of the functions do not crash with expected input.</p>
<p>As with the data preparation, the last step is to visualize the model performance.
With small sample data, we may not see anything interestin,
but sometimes already small number of datapoints can reveal interesting properties of the model when visualized.</p>
<p>You can also define functions for visualizing the model performance, and export them to the model module,
or include them directly as part of your machine learning model class if you see benefits from it.
Either way, it's better to test them too with the toy data before the real deal!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Quite often we would like to see how a model performs when the number of data is increased.
The two common questions are:</p>
<ol>
<li><p>How much data is needed that the model is accurate?</p>
</li>
<li><p>How much data we can put in the model and still be able to run it with our resources?</p>
</li>
</ol>
<p>Then, we might have to balance between these two.</p>
<p>So, for our example, let's loop through a range of data points, fit and time the model at each round</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>  <span class="c1"># library for checking time</span>

<span class="n">lgr</span> <span class="o">=</span> <span class="n">LogisticRegressionClassifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># dataframe to save results</span>
<span class="n">eval_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">lgr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span>

    <span class="n">begin</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># measure time before model is optimized</span>
    <span class="n">lgr</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># measure time after optimization</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;round&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">10</span><span class="p">],</span>
            <span class="s2">&quot;n_obs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">lgr</span><span class="o">.</span><span class="n">get_data</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
            <span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">lgr</span><span class="o">.</span><span class="n">get_train_loss</span><span class="p">()],</span>
            <span class="s2">&quot;test_loss&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">lgr</span><span class="o">.</span><span class="n">get_test_loss</span><span class="p">()],</span>
            <span class="s2">&quot;optimized_C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">lgr</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s2">&quot;estimator__C&quot;</span><span class="p">]],</span>
            <span class="s2">&quot;optimization_time&quot;</span><span class="p">:</span> <span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">,</span>  <span class="c1"># time spent in optimization</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="n">eval_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">eval_df</span><span class="p">,</span> <span class="n">ret</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">eval_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;round&quot;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">eval_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/anaconda/envs/templateenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.
  warnings.warn((&#34;The least populated class in y has only %d&#34;
/anaconda/envs/templateenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.
  warnings.warn((&#34;The least populated class in y has only %d&#34;
/anaconda/envs/templateenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.
  warnings.warn((&#34;The least populated class in y has only %d&#34;
/anaconda/envs/templateenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.
  warnings.warn((&#34;The least populated class in y has only %d&#34;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see, the stratification gives some warnings with such a small test set.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now you can also visualize the results. Super simple example:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">eval_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;n_obs&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Remember that in you application you might be interested in completely different measures!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Output-of-this-notebook">Output of this notebook<a class="anchor-link" href="#Output-of-this-notebook"> </a></h2><p>The result of this notebook is a collection methods ready for evaluation with the real data.</p>
<p>You should export classes and functions to <code>model.py</code> with <code># nbdev_build_lib</code> (workflows will do this automatically).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="You-can-move-on-to-loss-notebook!">You can move on to loss notebook!<a class="anchor-link" href="#You-can-move-on-to-loss-notebook!"> </a></h2>
</div>
</div>
</div>
</div>
 

