{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data\n",
    "%load_ext lab_black\n",
    "# nb_black if running in jupyter\n",
    "%load_ext autoreload\n",
    "# automatically reload python modules if there are changes in the\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotheses Space\n",
    "\n",
    "***input***: toy dataset from data-notebook\n",
    "\n",
    "***output***: ML model / simulation / analytics python module\n",
    "\n",
    "***description:***\n",
    "\n",
    "A hypotheses space defines the possible machine learning models, simulations or analytics tools applied to your problem. \n",
    "In this notebook you define the hypotheses space. If you are doing anyhting more complicated than just fitting existing well defined models such as defined in sklearn,\n",
    "it is recommended that you create a base class for the whole hypotheses space where you define core function handles,\n",
    "and implement the functions in subclasses that inherit from the base class. If the methods are complicated or you are \n",
    "comparing multiple methods that are inheritantly different by nature, you can separate models or subclasses to different notebooks similar to this.\n",
    "Adjust the running number in the beginning of the notebook name to your needs for retaining logical order.\n",
    "You should also unit test the classes created in this notebook with either toy data or small sample of your training data.\n",
    "Remember to add `# export` to top of all cells containing functions or classes that you have defined and want to use outside this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import toy data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1age</th>\n      <th>x4trestbps</th>\n      <th>x8thalach</th>\n      <th>x10oldpeak</th>\n      <th>y1num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.0</td>\n      <td>120.0</td>\n      <td>158.0</td>\n      <td>1.6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57.0</td>\n      <td>110.0</td>\n      <td>126.0</td>\n      <td>1.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59.0</td>\n      <td>170.0</td>\n      <td>140.0</td>\n      <td>3.4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41.0</td>\n      <td>125.0</td>\n      <td>176.0</td>\n      <td>1.6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>62.0</td>\n      <td>120.0</td>\n      <td>134.0</td>\n      <td>-0.8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>63.0</td>\n      <td>150.0</td>\n      <td>154.0</td>\n      <td>3.7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>51.0</td>\n      <td>94.0</td>\n      <td>154.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>39.0</td>\n      <td>94.0</td>\n      <td>179.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>58.0</td>\n      <td>115.0</td>\n      <td>138.0</td>\n      <td>0.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46.0</td>\n      <td>100.0</td>\n      <td>133.0</td>\n      <td>-2.6</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   x1age  x4trestbps  x8thalach  x10oldpeak  y1num\n0   50.0       120.0      158.0         1.6      0\n1   57.0       110.0      126.0         1.5      0\n2   59.0       170.0      140.0         3.4      1\n3   41.0       125.0      176.0         1.6      1\n4   62.0       120.0      134.0        -0.8      1\n5   63.0       150.0      154.0         3.7      1\n6   51.0        94.0      154.0         0.0      0\n7   39.0        94.0      179.0         0.0      0\n8   58.0       115.0      138.0         0.5      1\n9   46.0       100.0      133.0        -2.6      1"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df = pd.read_csv(\n",
    "    \"data/preprocessed_data/dataset_toy_switzerland_cleveland.csv\", index_col=0\n",
    ")\n",
    "toy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin with a simple script before constructing the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[0.5  0.25]\n",
      "Best Estimator: \n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', LogisticRegression(C=166.81005372000558))])\n",
      "\n",
      "Best Parameters: \n",
      "{'estimator__C': 166.81005372000558}\n",
      "\n",
      "Best Test Score: \n",
      "0.5\n",
      "\n",
      "Best Training Score: \n",
      "1.0\n",
      "\n",
      "All Training Scores: \n",
      "[0.875 0.875 0.875 0.875 0.875 1.    1.    1.    1.    1.   ]\n",
      "\n",
      "All Test Scores: \n",
      "[0.375 0.375 0.375 0.375 0.375 0.375 0.375 0.5   0.5   0.5  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = toy_df.iloc[:, :-1]\n",
    "y = toy_df.iloc[:, -1]\n",
    "\n",
    "k = 2\n",
    "seed = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1 / 5, random_state=seed, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lgr = LogisticRegression()\n",
    "pipe = Pipeline([(\"scaler\", scaler), (\"estimator\", lgr)])\n",
    "pipe.fit(X_train, y_train)\n",
    "print(pipe.score(X_test, y_test))\n",
    "\n",
    "cv = StratifiedKFold(n_splits=k)\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=cv))\n",
    "\n",
    "## optimize\n",
    "param_grid = {\n",
    "    \"estimator__C\": np.logspace(-4, 4, 10),\n",
    "}\n",
    "\n",
    "pipe_lgr = pipe  # make_pipeline(Imputer(),StandardScaler(),PCA(n_components=2),SVC(random_state=1))\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=5)\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe_lgr,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Estimator: \\n{}\\n\".format(gs.best_estimator_))\n",
    "print(\"Best Parameters: \\n{}\\n\".format(gs.best_params_))\n",
    "print(\"Best Test Score: \\n{}\\n\".format(gs.best_score_))\n",
    "print(\n",
    "    \"Best Training Score: \\n{}\\n\".format(\n",
    "        gs.cv_results_[\"mean_train_score\"][gs.best_index_]\n",
    "    )\n",
    ")\n",
    "print(\"All Training Scores: \\n{}\\n\".format(gs.cv_results_[\"mean_train_score\"]))\n",
    "print(\"All Test Scores: \\n{}\\n\".format(gs.cv_results_[\"mean_test_score\"]))\n",
    "# # This prints out all results during Cross-Validation in details\n",
    "# print(\"All Meta Results During CV Search: \\n{}\\n\".format(gs.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define base class for hypotheses space / simulations / analytics\r\n",
    "\r\n",
    "> How to create tidy class functions?\r\n",
    "- If the function performs a transformation on data, it should return the transformation. A transformation does not make changes to the model attributes.\r\n",
    "- If the function performs a side-effect, it should return reference to self, so that the functions can be piped. A side effect makes changes to the model attributes.\r\n",
    "- Transformations and side effects should not be mixed. A function should only perform one.\r\n",
    "\r\n",
    "For example the pipe `model.optimize().predict(X, y)` first performs a side effect `.optimize()` and then a transformation `.predict(X, y)`.\r\n",
    "The optimization function changes model parameters permanently, and the predict function only makes a transformation on the input data.\r\n",
    "However, a side effect may require input and a transformation does not always require input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\r\n",
    "class MachineLearningModel():\r\n",
    "    \"\"\"\r\n",
    "    Overly simplified example for a base class: basically just function name definitions\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, X, y):\r\n",
    "        self.X = X\r\n",
    "        self.y = y\r\n",
    "    def _set_data(self, X, y):\r\n",
    "        pass\r\n",
    "    def get_data(self):\r\n",
    "        pass\r\n",
    "    def _create_train_test_data(self):\r\n",
    "        pass\r\n",
    "    def get_train_test_data(self):\r\n",
    "        pass\r\n",
    "    def fit(self, X = None, y = None, **fit_params):\r\n",
    "        pass\r\n",
    "    def predict(self, X, y):\r\n",
    "        pass\r\n",
    "    def score(self):\r\n",
    "        pass\r\n",
    "    def optimize(self):\r\n",
    "        pass\r\n",
    "    def get_optimized_params(self):\r\n",
    "        pass\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define subclasses & functions\r\n",
    "\r\n",
    "you should also define the loss function used for model fitting\r\n",
    "\r\n",
    "don't forget to unit test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\r\n",
    "class LogisticRegressionClassifier(MachineLearningModel):\r\n",
    "    \"\"\"\r\n",
    "    Logistic regression classifier\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, X, y):\r\n",
    "\r\n",
    "        self.super(LogisticRegressionClassifier).__init__(X, y)\r\n",
    "\r\n",
    "        self.k = 2 # k-fold \r\n",
    "        self.seed = 0\r\n",
    "\r\n",
    "        self._create_train_test_data(X, y)\r\n",
    "\r\n",
    "        self.optimized_params = None\r\n",
    "\r\n",
    "        self.train_score = None\r\n",
    "        self.test_score = None\r\n",
    "\r\n",
    "        self.scaler = StandardScaler()\r\n",
    "        self.model = LogisticRegression()\r\n",
    "        self.pipe = Pipeline([(\"scaler\", self.scaler), (\"estimator\", self.model)])\r\n",
    "\r\n",
    "        self.fit()\r\n",
    "\r\n",
    "        self.cv = StratifiedKFold(n_splits=k)\r\n",
    "\r\n",
    "        # param grid for optimization\r\n",
    "        self.param_grid = {\r\n",
    "            \"estimator__C\": np.logspace(-4, 4, 10),\r\n",
    "        }\r\n",
    "\r\n",
    "        # define optimization method for optimizing the model\r\n",
    "        self.optimization_pipe = GridSearchCV(\r\n",
    "            estimator=self.pipe,\r\n",
    "            param_grid=self.param_grid,\r\n",
    "            scoring=\"accuracy\",\r\n",
    "            cv=self.cv,\r\n",
    "            return_train_score=True,\r\n",
    "        )\r\n",
    "\r\n",
    "    def _set_data(self, X, y):\r\n",
    "        \"\"\"\r\n",
    "        Set traing and evaluation data\r\n",
    "        \"\"\"\r\n",
    "        self.X = X.copy()\r\n",
    "        self.y = y.copy()\r\n",
    "\r\n",
    "        return self\r\n",
    "\r\n",
    "    def get_data(self) -> np.ndarray, np.ndarray:\r\n",
    "        \"\"\"\r\n",
    "        Get training and evaluation data\r\n",
    "        \"\"\"\r\n",
    "        return self.X.copy(), self.y.copy()\r\n",
    "\r\n",
    "    def _create_train_test_data(self, k = None, seed = None):\r\n",
    "        \"\"\"\r\n",
    "        Recreate training and testing data\r\n",
    "        \"\"\"\r\n",
    "        if seed is None:\r\n",
    "            seed = self.seed\r\n",
    "        if k is None:\r\n",
    "            k = self.k\r\n",
    "\r\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\r\n",
    "            self.X, self.y, test_size=(1 / k), random_state=seed, stratify=self.y\r\n",
    "        )\r\n",
    "\r\n",
    "        return self\r\n",
    "    \r\n",
    "    def get_train_test_data(self):\r\n",
    "        \"\"\"\r\n",
    "        Return X_train, X_test, y_train, y_test\r\n",
    "        \"\"\"\r\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\r\n",
    "\r\n",
    "    def fit(self, X = None, y = None, **fit_params):\r\n",
    "        \"\"\"\r\n",
    "        Train and evaluate model\r\n",
    "        \"\"\"\r\n",
    "        if X is None or y is None:\r\n",
    "            self.pipe.fit(self.X_train, self.y_train, fit_params)\r\n",
    "            \r\n",
    "        else: # reset data, recreate training and testing data and call fit again\r\n",
    "            self._set_data(X,y)\r\n",
    "            self._create_train_test_data()\r\n",
    "            self.fit(fit_params = fit_params)\r\n",
    "\r\n",
    "        return self\r\n",
    "\r\n",
    "    def predict(self, X, y):\r\n",
    "        \"\"\"\r\n",
    "        Get predicted value at X\r\n",
    "        \"\"\"\r\n",
    "        return self.pipe.predict(X, y)\r\n",
    "\r\n",
    "    def score(self)->dict:\r\n",
    "        \"\"\"\r\n",
    "        Return score (evaluation metric) for train and test data\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        self.train_score = pipe.score(self.X_train, self.y_train)\r\n",
    "        self.test_score = pipe.score(self.X_test, self.y_test)\r\n",
    "        \r\n",
    "        return {\r\n",
    "            \"train_score\": self.train_score.copy(),\r\n",
    "            \"test_score\": self.test_score.copy(),\r\n",
    "        }\r\n",
    "\r\n",
    "    def optimize(self):\r\n",
    "        \"\"\"\r\n",
    "        Optimize model hyperparameters and fit the model with optimized parameters.\r\n",
    "\r\n",
    "        This example is with GridSearchCV, but more efficient algorithms can be implemented in practice.\r\n",
    "        \"\"\"\r\n",
    "        self.optimization_pipe.fit(self.X_train, self.y_train)\r\n",
    "    \r\n",
    "        self.optimized_params = self.optimization_pipe.best_params_\r\n",
    "\r\n",
    "        self.fit(fit_params= self.optimized_params)\r\n",
    "\r\n",
    "        return self\r\n",
    "    \r\n",
    "    def get_optimized_params(self):\r\n",
    "\r\n",
    "        return self.optimized_params\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gs = optimization pipe\r\n",
    "#print(\"Best Estimator: \\n{}\\n\".format(gs.best_estimator_))\r\n",
    "#print(\"Best Parameters: \\n{}\\n\".format(gs.best_params_))\r\n",
    "#print(\"Best Test Score: \\n{}\\n\".format(gs.best_score_))\r\n",
    "#print(\r\n",
    "#    \"Best Training Score: \\n{}\\n\".format(\r\n",
    "#        gs.cv_results_[\"mean_train_score\"][gs.best_index_]\r\n",
    "#    )\r\n",
    "#)\r\n",
    "#print(\"All Training Scores: \\n{}\\n\".format(gs.cv_results_[\"mean_train_score\"]))\r\n",
    "#print(\"All Test Scores: \\n{}\\n\".format(gs.cv_results_[\"mean_test_score\"]))\r\n",
    "# # This prints out all results during Cross-Validation in details\r\n",
    "# print(\"All Meta Results During CV Search: \\n{}\\n\".format(gs.cv_results_))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model behaviour with toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of this notebook\r\n",
    "\r\n",
    "The result of this notebook is a collection methods ready for evaluation with the real data.\r\n",
    "\r\n",
    "the methods should be exported with `nbdev_build_lib`, but in the future this will be automatically handled by the pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (templateenv)",
   "language": "python",
   "name": "templateenv_py3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
