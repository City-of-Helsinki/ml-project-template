{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data\n",
    "%load_ext lab_black\n",
    "# nb_black if running in jupyter\n",
    "%load_ext autoreload\n",
    "# automatically reload python modules if there are changes in the\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "***input***: toy dataset from data-notebook\n",
    "\n",
    "***output***: ML model / simulation / analytics python module\n",
    "\n",
    "***description:***\n",
    "\n",
    "A hypotheses space defines the possible machine learning models, simulations or analytics tools considered for a ML problem. \n",
    "In this notebook you define the hypotheses space. This notebook contains an example ML model for classifying the heart disease dataset. \n",
    "\n",
    "If you are doing anyhting more complicated than just fitting existing well defined models such as defined in sklearn,\n",
    "it is recommended that you create a base class for the whole hypotheses space where you define core function handles,\n",
    "and implement the functions in subclasses that inherit from the base class.\n",
    "This is demonstrated in this notebook, even though it wouldn't be necessary for such a simple function.\n",
    "\n",
    "If the methods are complicated or you are comparing multiple methods that are inheritantly different by nature, \n",
    "you can also separate models or subclasses to different notebooks similar to this.\n",
    "Adjust the running number in the beginning of the notebook name to your needs for retaining logical order.\n",
    "You should also unit test the classes created in this notebook with either toy data created in data notebook, or randomly generated test data.\n",
    "\n",
    "Remember to add `# export` to top of all cells containing functions or classes that you have defined and want to use outside this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import toy data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1age</th>\n      <th>x4trestbps</th>\n      <th>x8thalach</th>\n      <th>x10oldpeak</th>\n      <th>y1num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.0</td>\n      <td>120.0</td>\n      <td>158.0</td>\n      <td>1.6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57.0</td>\n      <td>110.0</td>\n      <td>126.0</td>\n      <td>1.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59.0</td>\n      <td>170.0</td>\n      <td>140.0</td>\n      <td>3.4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41.0</td>\n      <td>125.0</td>\n      <td>176.0</td>\n      <td>1.6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>62.0</td>\n      <td>120.0</td>\n      <td>134.0</td>\n      <td>-0.8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>63.0</td>\n      <td>150.0</td>\n      <td>154.0</td>\n      <td>3.7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>51.0</td>\n      <td>94.0</td>\n      <td>154.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>39.0</td>\n      <td>94.0</td>\n      <td>179.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>58.0</td>\n      <td>115.0</td>\n      <td>138.0</td>\n      <td>0.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>46.0</td>\n      <td>100.0</td>\n      <td>133.0</td>\n      <td>-2.6</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   x1age  x4trestbps  x8thalach  x10oldpeak  y1num\n0   50.0       120.0      158.0         1.6      0\n1   57.0       110.0      126.0         1.5      0\n2   59.0       170.0      140.0         3.4      1\n3   41.0       125.0      176.0         1.6      1\n4   62.0       120.0      134.0        -0.8      1\n5   63.0       150.0      154.0         3.7      1\n6   51.0        94.0      154.0         0.0      0\n7   39.0        94.0      179.0         0.0      0\n8   58.0       115.0      138.0         0.5      1\n9   46.0       100.0      133.0        -2.6      1"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df = pd.read_csv(\n",
    "    \"data/preprocessed_data/dataset_toy_switzerland_cleveland.csv\", index_col=0\n",
    ")\n",
    "toy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin with a simple script before constructing the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[0.5  0.25]\n",
      "Best Estimator: \n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', LogisticRegression(C=166.81005372000558))])\n",
      "\n",
      "Best Parameters: \n",
      "{'estimator__C': 166.81005372000558}\n",
      "\n",
      "Best Test Score: \n",
      "0.5\n",
      "\n",
      "Best Training Score: \n",
      "1.0\n",
      "\n",
      "All Training Scores: \n",
      "[0.875 0.875 0.875 0.875 0.875 1.    1.    1.    1.    1.   ]\n",
      "\n",
      "All Test Scores: \n",
      "[0.375 0.375 0.375 0.375 0.375 0.375 0.375 0.5   0.5   0.5  ]\n",
      "\n",
      "Test score with best params (should equal to Best Test Score above)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "X = toy_df.iloc[:, :-1]  # .to_numpy()\n",
    "y = toy_df.iloc[:, -1]  # .to_numpy()\n",
    "\n",
    "k = 2\n",
    "seed = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1 / 5, random_state=seed, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lgr = LogisticRegression()\n",
    "pipe = Pipeline([(\"scaler\", scaler), (\"estimator\", lgr)])\n",
    "pipe.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    ")\n",
    "print(pipe.score(X_test, y_test))\n",
    "\n",
    "cv = StratifiedKFold(n_splits=k)\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=cv))\n",
    "\n",
    "## optimize\n",
    "param_grid = {\n",
    "    \"estimator__C\": np.logspace(-4, 4, 10),\n",
    "}\n",
    "\n",
    "# make_pipeline(Imputer(),StandardScaler(),PCA(n_components=2),SVC(random_state=1))\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=5)\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Estimator: \\n{}\\n\".format(gs.best_estimator_))\n",
    "print(\"Best Parameters: \\n{}\\n\".format(gs.best_params_))\n",
    "print(\"Best Test Score: \\n{}\\n\".format(gs.best_score_))\n",
    "print(\n",
    "    \"Best Training Score: \\n{}\\n\".format(\n",
    "        gs.cv_results_[\"mean_train_score\"][gs.best_index_]\n",
    "    )\n",
    ")\n",
    "print(\"All Training Scores: \\n{}\\n\".format(gs.cv_results_[\"mean_train_score\"]))\n",
    "print(\"All Test Scores: \\n{}\\n\".format(gs.cv_results_[\"mean_test_score\"]))\n",
    "# # This prints out all results during Cross-Validation in details\n",
    "# print(\"All Meta Results During CV Search: \\n{}\\n\".format(gs.cv_results_))\n",
    "\n",
    "# Reset pipeline with best params\n",
    "pipe.set_params(estimator__C=gs.best_params_[\"estimator__C\"])\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Test score with best params (should equal to Best Test Score above)\")\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define base class for hypotheses space / simulations / analytics\r\n",
    "\r\n",
    "> How to create tidy class functions?\r\n",
    "- If the function performs a transformation on data, it should return the transformation. A transformation does not make changes to the model attributes.\r\n",
    "- If the function performs a side-effect, it should return reference to self, so that the functions can be piped. A side effect makes changes to the model attributes.\r\n",
    "- Transformations and side effects should not be mixed. A function should only perform one.\r\n",
    "\r\n",
    "For example the pipe `model.optimize().predict(X, y)` first performs a side effect `.optimize()` and then a transformation `.predict(X, y)`.\r\n",
    "The optimization function changes model parameters permanently, and the predict function only makes a transformation on the input data.\r\n",
    "However, a side effect may require input and a transformation does not always require input. \r\n",
    "\r\n",
    "Here we define the base class `MachineLearningModel` that holds some simple functions for handling data, that would be common for all subclasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MachineLearningModel:\n",
    "    \"\"\"\n",
    "    Overly simplified example for a base class: basically just function handle definitions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.k = 5  # k-fold n_splits\n",
    "        self.seed = 0\n",
    "        self.set_data(X, y)\n",
    "\n",
    "    def set_data(self, X, y):\n",
    "        \"\"\"\n",
    "        Set traing and evaluation data\n",
    "        \"\"\"\n",
    "        self.X = X.copy()\n",
    "        self.y = y.copy()\n",
    "\n",
    "        self.__create_train_test_data()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_data(self) -> (np.ndarray, np.ndarray):\n",
    "        \"\"\"\n",
    "        Get training and evaluation data\n",
    "        \"\"\"\n",
    "        return self.X.copy(), self.y.copy()\n",
    "\n",
    "    def __create_train_test_data(self, k=None, seed=None):\n",
    "        \"\"\"\n",
    "        Create training and testing data\n",
    "        \"\"\"\n",
    "        if seed is None:\n",
    "            seed = self.seed\n",
    "        if k is None:\n",
    "            k = self.k\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=(1 / k), random_state=seed, stratify=self.y\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_train_test_data(self):\n",
    "        \"\"\"\n",
    "        Return X_train, X_test, y_train, y_test\n",
    "        \"\"\"\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n",
    "    def fit(self, X=None, y=None, **fit_params):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "    def score(self):\n",
    "        pass\n",
    "\n",
    "    def optimize(self):\n",
    "        pass\n",
    "\n",
    "    def get_params(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test base class\r\n",
    "\r\n",
    "Purpose of unit testing is to cover all possible excecution paths in code.\r\n",
    "Unit testing helps developers to avoid and identify bugs in code.\r\n",
    "\r\n",
    "In this example python built-in `assert` is used for unit tests.\r\n",
    "The line after `assert` should return `True`, i.e. a non-zero object.\r\n",
    "0 or None object will raise an `AssertionError`. Note that `np.nan` does not raise the error.\r\n",
    "\r\n",
    "At the moment, nbdev considers all cells that do not have `# export` tag as tests. \r\n",
    "This is handy because you can now keep all your tests in the same file (notebook) with the code and documentation.\r\n",
    "The downside is, however, that at the moment there is no official solution for monitoring test coverage. \r\n",
    "If test coverage is required, one option would be to implement tests with  `pytest` or `unittest` and export the tests to separate test.py file.\r\n",
    "Nbdev allows marking slow cells with `# slow` tag so that they can be left out from commit test runs to speed up testing.\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test init\n",
    "mlmodel = MachineLearningModel(X, y)\n",
    "\n",
    "# test get_data\n",
    "assert mlmodel.get_data()[0].shape == X.shape\n",
    "assert mlmodel.get_data()[1][1] == y[1]\n",
    "\n",
    "# test __create_test_train_data and get_train_test_data\n",
    "assert np.ceil(\n",
    "    10 * mlmodel.get_train_test_data()[-1].shape[0] / mlmodel.get_data()[1].shape[0]\n",
    ") == np.ceil(10 / mlmodel.k)\n",
    "\n",
    "# test set_data\n",
    "assert (\n",
    "    MachineLearningModel(X, y)\n",
    "    .set_data(X.iloc[range(X.shape[0] - 1, -1, -1)], y)\n",
    "    .get_data()[0]\n",
    "    .iloc[0, 0]\n",
    ") == X.iloc[-1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define subclasses & functions\r\n",
    "\r\n",
    "A subclass or child class inherits all attributes and functions of a parent class, but may also have additional functions defined.\r\n",
    "\r\n",
    "Here we define an example of a subclass of `MachineLearningModel`, the `LogisticRegressionModel` which performs logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LogisticRegressionClassifier(MachineLearningModel):\n",
    "    \"\"\"\n",
    "    Logistic regression classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "        super(LogisticRegressionClassifier, self).__init__(X, y)\n",
    "\n",
    "        self.train_score = None\n",
    "        self.test_score = None\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = LogisticRegression()\n",
    "        self.pipe = Pipeline([(\"scaler\", self.scaler), (\"estimator\", self.model)])\n",
    "\n",
    "        self.cv = StratifiedKFold(n_splits=k)\n",
    "\n",
    "        # param grid for optimization\n",
    "        self.param_grid = {\n",
    "            \"estimator__C\": np.logspace(-4, 4, 10),\n",
    "        }\n",
    "\n",
    "        # define optimization method for optimizing the model\n",
    "        self.optimization_pipe = GridSearchCV(\n",
    "            estimator=self.pipe,\n",
    "            param_grid=self.param_grid,\n",
    "            scoring=\"accuracy\",\n",
    "            cv=self.cv,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        \"\"\"\n",
    "        Train and evaluate model\n",
    "        \"\"\"\n",
    "        if X is None or y is None:\n",
    "            self.pipe.fit(self.X_train, self.y_train)\n",
    "        else:  # reset data, recreate training and testing data and recursively call fit\n",
    "            self.set_data(X, y).fit()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Get predicted value at X\n",
    "        \"\"\"\n",
    "        return self.pipe.predict(X)\n",
    "\n",
    "    def score(self) -> dict:\n",
    "        \"\"\"\n",
    "        Return score (evaluation metric) for train and test data\n",
    "        \"\"\"\n",
    "\n",
    "        self.train_score = pipe.score(self.X_train, self.y_train)\n",
    "        self.test_score = pipe.score(self.X_test, self.y_test)\n",
    "\n",
    "        return {\n",
    "            \"train_score\": self.train_score.copy(),\n",
    "            \"test_score\": self.test_score.copy(),\n",
    "        }\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Optimize model hyperparameters and fit the model with optimized parameters.\n",
    "\n",
    "        This example is with GridSearchCV, but more efficient algorithms can be implemented in practice.\n",
    "        \"\"\"\n",
    "        self.optimization_pipe.fit(self.X_train, self.y_train)\n",
    "        self.pipe.set_params(\n",
    "            estimator__C=self.optimization_pipe.best_params_[\"estimator__C\"]\n",
    "        )\n",
    "        self.fit()\n",
    "        return self\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Return params\n",
    "        \"\"\"\n",
    "        return self.pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gs = optimization pipe\n",
    "# print(\"Best Estimator: \\n{}\\n\".format(gs.best_estimator_))\n",
    "# print(\"Best Parameters: \\n{}\\n\".format(gs.best_params_))\n",
    "# print(\"Best Test Score: \\n{}\\n\".format(gs.best_score_))\n",
    "# print(\n",
    "#    \"Best Training Score: \\n{}\\n\".format(\n",
    "#        gs.cv_results_[\"mean_train_score\"][gs.best_index_]\n",
    "#    )\n",
    "# )\n",
    "# print(\"All Training Scores: \\n{}\\n\".format(gs.cv_results_[\"mean_train_score\"]))\n",
    "# print(\"All Test Scores: \\n{}\\n\".format(gs.cv_results_[\"mean_test_score\"]))\n",
    "# # This prints out all results during Cross-Validation in details\n",
    "# print(\"All Meta Results During CV Search: \\n{}\\n\".format(gs.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [1 1 1 1 1 1 0 0 1 1]\n",
      "true     : [0 0 1 1 1 1 0 0 1 1]\n",
      "score: {'train_score': 1.0, 'test_score': 0.5}\n",
      "Optimizing model\n",
      "predicted: [1 0 1 1 1 1 0 0 1 1]\n",
      "true     : [0 0 1 1 1 1 0 0 1 1]\n",
      "score: {'train_score': 1.0, 'test_score': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('scaler', StandardScaler()),\n  ('estimator', LogisticRegression(C=166.81005372000558))],\n 'verbose': False,\n 'scaler': StandardScaler(),\n 'estimator': LogisticRegression(C=166.81005372000558),\n 'scaler__copy': True,\n 'scaler__with_mean': True,\n 'scaler__with_std': True,\n 'estimator__C': 166.81005372000558,\n 'estimator__class_weight': None,\n 'estimator__dual': False,\n 'estimator__fit_intercept': True,\n 'estimator__intercept_scaling': 1,\n 'estimator__l1_ratio': None,\n 'estimator__max_iter': 100,\n 'estimator__multi_class': 'auto',\n 'estimator__n_jobs': None,\n 'estimator__penalty': 'l2',\n 'estimator__random_state': None,\n 'estimator__solver': 'lbfgs',\n 'estimator__tol': 0.0001,\n 'estimator__verbose': 0,\n 'estimator__warm_start': False}"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test init\n",
    "lgr_model = LogisticRegressionClassifier(X, y)\n",
    "\n",
    "# test fit\n",
    "try:  # fit should be called before predict or score\n",
    "    lgr_model.predict([1, 1, 1, 1])\n",
    "except: # yes, you can also test what should not work!\n",
    "    pass\n",
    "try:\n",
    "    lgr_model.score()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "lgr_model.fit()  # should not break\n",
    "\n",
    "# test predict\n",
    "print(f\"predicted: {lgr_model.predict(X[::1])}\")\n",
    "print(f\"true     : {y[::1].values}\")\n",
    "\n",
    "# test score\n",
    "print(f\"score: {lgr_model.score()}\")\n",
    "\n",
    "# test optimize\n",
    "print(\"Optimizing model\")\n",
    "lgr_model.optimize()\n",
    "print(f\"predicted: {lgr_model.predict(X[::1])}\")\n",
    "print(f\"true     : {y[::1].values}\")\n",
    "print(f\"score: {lgr_model.score()}\")\n",
    "\n",
    "# test get_params\n",
    "lgr_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model behaviour with toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of this notebook\r\n",
    "\r\n",
    "The result of this notebook is a collection methods ready for evaluation with the real data.\r\n",
    "\r\n",
    "the methods should be exported with `nbdev_build_lib`, but in the future this will be automatically handled by the pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (templateenv)",
   "language": "python",
   "name": "templateenv_py3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
